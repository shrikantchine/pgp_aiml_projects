{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization\n",
    "import seaborn as sns\n",
    "\n",
    "#For preprocessing\n",
    "from sklearn.base import TransformerMixin\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import re, string, unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# For building pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(\"Tweets.csv\")\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = tweets_df[['text', 'airline_sentiment']]\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 0\n",
       "airline_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null data\n",
    "tweets_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "  airline_sentiment  \n",
       "0           neutral  \n",
       "1          positive  \n",
       "2           neutral  \n",
       "3          negative  \n",
       "4          negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 0 only space data\n"
     ]
    }
   ],
   "source": [
    "blanks = []\n",
    "for index, txt, sentiment in tweets_df.itertuples():\n",
    "    if (type(txt) == 'str' and txt.isspace()) or (type(sentiment) == 'str' and sentiment.isspace()):\n",
    "        blanks.append(index)\n",
    "        \n",
    "print(f\"The dataset contains {len(blanks)} only space data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight\n",
    "\n",
    "- The provided data does not contain any empty feature or label values\n",
    "- The data is biased towards negative tweets\n",
    "- All data in column text and airline_sentiment is just String data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Following words need to be removed from stopwords because they convey negative sentiments\n",
    "customlist = ['not', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn',\n",
    "        \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\n",
    "        \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
    "        \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "stopwords = list(set(stopwords) - set(customlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(TransformerMixin):\n",
    "    '''\n",
    "    This class is used to preprocess the text.\n",
    "    It extends TranformerMixin class so that it can be part of the pipeline.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df, **transform_params):\n",
    "        def helper(txt):\n",
    "            txt = self.remove_html(txt)\n",
    "            contractions.fix(txt)\n",
    "            txt = self.remove_numbers(txt)\n",
    "            tokens = self.tokenize(txt)\n",
    "            tokens = self.to_lower(tokens)\n",
    "            tokens = self.remove_stopwords(tokens)\n",
    "            tokens = self.remove_punct(tokens)\n",
    "            tokens = self.lemmetize(tokens)\n",
    "            return self.join(tokens)\n",
    "\n",
    "        df_copy = df.copy(deep=True)\n",
    "        df_copy = df_copy.apply(helper)\n",
    "        return df_copy\n",
    "    \n",
    "    def remove_html(self, txt):\n",
    "        return BeautifulSoup(txt, \"html.parser\").get_text()\n",
    "\n",
    "    def remove_numbers(self, txt):\n",
    "        return re.sub(r'\\d+', '', txt)\n",
    "    \n",
    "    def tokenize(self, txt):\n",
    "        return word_tokenize(txt)\n",
    "    \n",
    "    def remove_stopwords(self, lst_tokens):\n",
    "        return [word for word in lst_tokens if word not in stopwords]\n",
    "    \n",
    "    \n",
    "    def remove_punct(self, lst_token):\n",
    "        new_lst_tokens = []\n",
    "        for word in lst_token:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_lst_tokens.append(new_word)\n",
    "        return new_lst_tokens\n",
    "\n",
    "    \n",
    "    def to_lower(self, lst_token):\n",
    "        return [token.lower() for token in lst_token]\n",
    "    \n",
    "    def lemmetize(self, lst_token):\n",
    "        lemmetizer = WordNetLemmatizer()\n",
    "        return [lemmetizer.lemmatize(token, pos='v') for token in lst_token]\n",
    "    \n",
    "    def join(self, lst_token):\n",
    "        return ' '.join(lst_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "tweets_df_transformed = tweets_df.copy()\n",
    "tweets_df_transformed.drop('text', axis=1, inplace=True)\n",
    "\n",
    "tweets_df_transformed['text'] = preprocessor.fit_transform(tweets_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica dhepburn say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>virginamerica plus ve add commercials experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica nt today must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica s really aggressive blast obnoxious entertainment guests face little recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica s really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                          text  \n",
       "0                                                                   virginamerica dhepburn say  \n",
       "1                                       virginamerica plus ve add commercials experience tacky  \n",
       "2                                      virginamerica nt today must mean need take another trip  \n",
       "3  virginamerica s really aggressive blast obnoxious entertainment guests face little recourse  \n",
       "4                                                         virginamerica s really big bad thing  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "- Based on above, the transformer is working fine and is ready to be used as part of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_df['text'], tweets_df['airline_sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_score(vectorizer, models):\n",
    "    scores = {}\n",
    "    max_score = 0.0\n",
    "    max_y_pred = None\n",
    "\n",
    "    for model in models:\n",
    "        pipeline = make_pipeline(TextPreprocessor(), vectorizer, model)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        accuracy_score = np.mean(cross_val_score(pipeline, X_test, y_test, cv=10))\n",
    "        max_score = max(accuracy_score, max_score)\n",
    "        scores[model.__class__.__name__] = accuracy_score\n",
    "        if max_score == accuracy_score:\n",
    "            max_y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "    print(scores)\n",
    "    print(max_score)\n",
    "    print(metrics.classification_report(y_test, max_y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, max_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': 0.7768632221992131, 'MultinomialNB': 0.7481735348933527, 'RandomForestClassifier': 0.6407113273969767, 'GradientBoostingClassifier': 0.7500031062331746, 'LinearSVC': 0.7443057568854836, 'SVC': 0.7734536135845931}\n",
      "0.7768632221992131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.91      0.88      2814\n",
      "     neutral       0.64      0.56      0.59       884\n",
      "    positive       0.77      0.70      0.73       694\n",
      "\n",
      "    accuracy                           0.80      4392\n",
      "   macro avg       0.75      0.72      0.73      4392\n",
      "weighted avg       0.80      0.80      0.80      4392\n",
      "\n",
      "[[2551  194   69]\n",
      " [ 315  491   78]\n",
      " [ 120   88  486]]\n"
     ]
    }
   ],
   "source": [
    "build_score(CountVectorizer(), [\n",
    "    LogisticRegression(solver='liblinear'), \n",
    "    MultinomialNB(), \n",
    "    RandomForestClassifier(n_jobs=-1, random_state=42, max_depth=5), \n",
    "    GradientBoostingClassifier(random_state=42), \n",
    "    LinearSVC(), \n",
    "    SVC()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': 0.7668492441499275, 'MultinomialNB': 0.671220231932077, 'RandomForestClassifier': 0.6407113273969767, 'GradientBoostingClassifier': 0.7561518948022364, 'LinearSVC': 0.7675264029819838, 'SVC': 0.7695853178711949}\n",
      "0.7695853178711949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.95      0.87      2814\n",
      "     neutral       0.69      0.46      0.55       884\n",
      "    positive       0.83      0.62      0.71       694\n",
      "\n",
      "    accuracy                           0.80      4392\n",
      "   macro avg       0.78      0.68      0.71      4392\n",
      "weighted avg       0.79      0.80      0.78      4392\n",
      "\n",
      "[[2664  110   40]\n",
      " [ 428  407   49]\n",
      " [ 188   76  430]]\n"
     ]
    }
   ],
   "source": [
    "build_score(TfidfVectorizer(), [\n",
    "    LogisticRegression(solver='liblinear'), \n",
    "    MultinomialNB(), \n",
    "    RandomForestClassifier(n_jobs=-1, random_state=42, max_depth=5), \n",
    "    GradientBoostingClassifier(random_state=42), \n",
    "    LinearSVC(), \n",
    "    SVC()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "- Based on the above analysis, count vectorization and logistic regression works best according to accuracy score\n",
    "- But if we consider that this study is to correctly identify negative reviews (for improvement), Tfidf vectorizer with SVC works best.\n",
    "- Count vectorizer and Tfidf vectorizer are computationally very slow. So, we need to use some hyperparameters for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVC': 0.7741354317664112}\n",
      "0.7741354317664112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.94      0.88      2814\n",
      "     neutral       0.69      0.48      0.57       884\n",
      "    positive       0.82      0.63      0.71       694\n",
      "\n",
      "    accuracy                           0.80      4392\n",
      "   macro avg       0.78      0.69      0.72      4392\n",
      "weighted avg       0.79      0.80      0.79      4392\n",
      "\n",
      "[[2655  115   44]\n",
      " [ 404  427   53]\n",
      " [ 183   73  438]]\n"
     ]
    }
   ],
   "source": [
    "build_score(TfidfVectorizer(max_features=2000, max_df=0.95), [SVC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vader_sentiment.vader_sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "tweets_df_transformed['vader_score'] = tweets_df_transformed['text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "tweets_df_transformed['vader_sentiment'] = tweets_df_transformed['vader_score'].apply(\n",
    "    lambda c: 'positive' if c > 0 else ('neutral' if c == 0 else 'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5183060109289618"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(tweets_df_transformed['airline_sentiment'], tweets_df_transformed['vader_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['vader_score'] = tweets_df['text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "tweets_df['vader_sentiment'] = tweets_df['vader_score'].apply(lambda c: 'positive' if c > 0 else ('neutral' if c == 0 else 'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.546448087431694"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(tweets_df['airline_sentiment'], tweets_df['vader_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight\n",
    "\n",
    "While vader segmentation does not provide good results on both transformed and unprocessed data, it still offers better better prediction that random guessing. <br />\n",
    "We can conclude that Vader analysis is not suitable for the provided data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit94459e2fb27840e19039c0142dc60d67"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
